{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading of shapely/geopandas failed. Geometric functions will not work\n",
      "Loading of geopandas/shapely failed. Geometric functions will not work\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from klimaatbestendige_netwerken.pyBIVAS_plot import pyBIVAS_plot as pyBIVAS\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "knelpunt_arcs = {\n",
    "    \n",
    "    'BR_Lobith': 9204, \n",
    "    'WA_Erlecom': 6332,\n",
    "    'WA_Nijmegen': 6321,\n",
    "    'WA_Ewijk': 7046,\n",
    "    'WA_Ophemert': 8871,\n",
    "    'WA_St. Andries': 7362,\n",
    "    'WA_Zaltbommel': 7265,\n",
    "    \n",
    "    'NRL_Arnhem': 6621,\n",
    "    \n",
    "    'MWK_Weurt': 6325,\n",
    "    'ARK_Tiel': 1705,\n",
    "    'TK_Eefde': 5771,\n",
    "    \n",
    "    'MA_Niftrik': 7391,\n",
    "    'MA_Mook': 7526,\n",
    "    \n",
    "    'IJ_Velp': 6510,\n",
    "    'IJ_Brummen': 5916,\n",
    "    'IJ_Wilp': 5699,\n",
    "    'IJ_Terwolde': 5476,\n",
    "    'IJ_Wapenveld': 4567,\n",
    "    'IJ_Zalk': 3855,\n",
    "    \n",
    "    'DL_Emmerich': 21116,\n",
    "    'DL_Ruhrort': 20552,\n",
    "    'DL_Kaub': 20249,\n",
    "    \n",
    "}\n",
    "knelpunt_arcs_array = list(knelpunt_arcs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputdir = Path('preprocessing_KBN_v0.2')\n",
    "# outputdir.mkdir(exist_ok=True)\n",
    "\n",
    "# BIVAS_results_folder = Path(r'n:\\Projects\\11203500\\11203738\\B. Measurements and calculations\\WP5 Hoofdvaarwegennet\\Scheepvaartmodellering\\BIVAS_results')\n",
    "\n",
    "# B = pyBIVAS(BIVAS_results_folder / 'Bivas_Run3 Q Q1800 T Ref_2014.db')\n",
    "# B.set_scenario(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir = Path('preprocessing_KBN_v0.2_WLO2050_hoog')\n",
    "outputdir.mkdir(exist_ok=True)\n",
    "\n",
    "BIVAS_results_folder = Path(r'n:\\Projects\\11203500\\11203738\\B. Measurements and calculations\\WP5 Hoofdvaarwegennet\\Scheepvaartmodellering\\BIVAS_results')\n",
    "\n",
    "B = pyBIVAS(BIVAS_results_folder / 'Bivas_Run3 Q Q1800 T WLO2050_Hoog.db')\n",
    "B.set_scenario(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.network_arcs(outputfileshape=outputdir / 'arcs.json');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export locations\n",
    "knelpunt_to_shape = B.arcs.loc[knelpunt_arcs_array][['geometry']]\n",
    "knelpunt_to_shape['name'] = knelpunt_arcs.keys()\n",
    "knelpunt_to_shape['geometry'] = B.arcs.geometry.apply(lambda x: x.centroid)\n",
    "knelpunt_to_shape.to_json(outputdir / 'arcs_knelpunten.json', default_handler=str)\n",
    "\n",
    "# knelpunt_to_shape['geometry'] = knelpunt_to_shape['geometry'].centroid\n",
    "# knelpunt_to_shape.reset_index().to_file(outputdir / 'arcs_knelpunten.json', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get results for all trips\n",
    "trips = B.routestatistics_advanced(group_by=['TripsID'])\n",
    "trips.to_json(outputdir / 'trips.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 397861/397861 [39:25<00:00, 168.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get for each trip which knelpunten are passed (this takes approx. 1 hour to compute)\n",
    "knelpunt_route = {}\n",
    "for t_id in tqdm(trips.index):\n",
    "    route_arcs = B.route_arcs(t_id)\n",
    "    \n",
    "    knelpunt_route[t_id] = np.isin(knelpunt_arcs_array, route_arcs.ArcID.to_list())\n",
    "    \n",
    "knelpunt_route = pd.DataFrame(knelpunt_route).T\n",
    "knelpunt_route.columns = knelpunt_arcs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trips per route\n",
    "temp = knelpunt_route.copy()\n",
    "temp['nTrips'] = trips['NumberOfTrips']\n",
    "count_combinations = temp.groupby(knelpunt_route.columns.to_list(), axis=0)['nTrips'].sum()\n",
    "count_combinations.to_csv(outputdir / 'route_ntrips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Number of possible combinations\n",
    "# total_number_combinations = 2 ** (len(knelpunt_arcs))\n",
    "# total_number_combinations\n",
    "\n",
    "# from itertools import chain, combinations\n",
    "\n",
    "# def powerset(iterable):\n",
    "#     \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "#     s = list(iterable)\n",
    "#     return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "# # all possible combinations\n",
    "# all_combinations = list(powerset(list(knelpunt_arcs.keys())))\n",
    "# len(all_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dictionary of trip_ids per unique route \n",
    "\n",
    "# Get for each combination of columns the indices with this combination\n",
    "i_per_group = knelpunt_route.groupby(knelpunt_route.columns.to_list(), axis=0).indices\n",
    "\n",
    "# Rename index from boolean to set of knelpunten\n",
    "# Rename values from index to trip_id\n",
    "i_per_group = {frozenset(knelpunt_route.columns[list(i)]): knelpunt_route.index[indices]  for i, indices in i_per_group.items()}\n",
    "\n",
    "# Write to json, this file is not really used later on (first convert, than write)\n",
    "with open(outputdir / 'route_tripid.json', 'w') as fout:\n",
    "    simple_dict = {\",\".join(list(k)): list([int(l) for l in v]) for k, v in i_per_group.items()}\n",
    "    json.dump(simple_dict, fout, indent=2)\n",
    "\n",
    "# Show the results\n",
    "# pd.Series({k: len(v) for k, v in i_per_group.items()}).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read QH per knelpunt\n",
    "waterscenario_folder = Path(r'n:\\Projects\\11203500\\11203738\\B. Measurements and calculations\\WP5 Hoofdvaarwegennet\\Scheepvaartmodellering\\Waterscenario\\create_rerun_after_report')\n",
    "\n",
    "QH = {}\n",
    "QQ = {}\n",
    "\n",
    "for Q in [700, 850, 1020, 1400, 1800]:\n",
    "    data = pd.read_csv(waterscenario_folder / f'waterscenario_15_Q{Q}.csv')\n",
    "    data = data.set_index('ArcID').reindex(knelpunt_arcs_array)\n",
    "    QH[Q] = data['WaterDepth__m']\n",
    "    QQ[Q] = data['RateOfFlow__m3_s']\n",
    "    \n",
    "QH = pd.concat(QH, axis=1)\n",
    "QH = QH.fillna(9)\n",
    "QH.index = knelpunt_arcs.keys()\n",
    "\n",
    "# QH.to_json(outputdir / 'knelpunt_discharge_waterdepth.json', orient='index', indent=2)\n",
    "\n",
    "QQ = pd.concat(QQ, axis=1)\n",
    "QQ.index = knelpunt_arcs.keys()\n",
    "QQ = QQ.replace({0: np.nan})\n",
    "\n",
    "# Fill nans with Lobith values\n",
    "QQ = QQ.fillna({Q:Q for Q in QQ.columns})\n",
    "\n",
    "# QQ.to_json(outputdir / 'knelpunt_discharge_waterdepth.json', orient='index', indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'preprocessing_KBN_v0.2_WLO2050_hoog\\\\input\\\\Depth.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-58bcea1363d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Zelfde gegevens, maar dan al geexporteerd:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdepth_DL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputdir\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34mr'input\\Depth.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mdepth_DL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdepth_DL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Duisburg-Ruhrort'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Ruhrort'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Miniconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'preprocessing_KBN_v0.2_WLO2050_hoog\\\\input\\\\Depth.csv'"
     ]
    }
   ],
   "source": [
    "# Handmatige toevoegingen:\n",
    "\n",
    "# From De Jong (2020). Digital Twin Waterways: Water levels and water depths on the river Rhine. Deltares memo 11205224-000-ZWS-0011, v1.0 d.d. 12 august 2020\n",
    "\n",
    "## NOT GOOD. TOO MUCH ROUNDING!!\n",
    "\n",
    "# additional_depth_functions = {\n",
    "# \t'Kaub': lambda Q: 12.20 * Q**0.08 - 21.02 + -1.12,\n",
    "# \t'Ruhrort': lambda Q: 0.07**0.58 - 1.47 + -0.47,\n",
    "# \t'Emmerich': lambda Q: 0.10**0.53 - 3.28 + -1.96\n",
    "# }\n",
    "\n",
    "# Zelfde gegevens, maar dan al geexporteerd:\n",
    "depth_DL = pd.read_csv(outputdir / r'input\\Depth.csv', index_col=0)\n",
    "depth_DL = depth_DL.rename(columns={'Duisburg-Ruhrort': 'Ruhrort'})\n",
    "\n",
    "Q = QH.columns\n",
    "for name in ['Kaub', 'Ruhrort', 'Emmerich']:\n",
    "    QH.loc[f'DL_{name}'] = np.interp(Q, depth_DL.index, depth_DL[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zie tabel 2.2 van pot blootstelling Maas\n",
    "QH.loc['MA_Niftrik'] = 3.2 * 1.4\n",
    "QH.loc['MA_Mook']= 3 * 1.4 # eigenlijk pas na Venlo, daarvoor nog 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manual create json\n",
    "QH_json = {}\n",
    "for k in QH.index:\n",
    "    QH_json[k] = {np.round(Q, 0): np.round(H, 3) for Q, H in zip(QQ.loc[k].values, QH.loc[k].values)}\n",
    "\n",
    "outputfile = outputdir / 'knelpunt_discharge_waterdepth.json'\n",
    "with open(outputfile, 'w') as fout:\n",
    "    fout.write(json.dumps(QH_json, indent=2))\n",
    "# Test read function\n",
    "# pd.read_json(outputdir / 'knelpunt_discharge_waterdepth.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VD-EUR per corridor\n",
    "\n",
    "def costs(trips, depth):\n",
    "    \"\"\"\n",
    "    Compute costs (and more) for list of trips if the depth is lower than :\n",
    "    \n",
    "      trips: output from pyBIVAS (routestatistics_advanced(group_by=['TripsID'])) or a subset of this data [DataFrame]\n",
    "      depth: given depth [float]\n",
    "    \n",
    "    returns: [float]\n",
    "      effect: number of trips affected by limiting water depth\n",
    "      effect: loss in tonnage due to limiting water depth\n",
    "      effect: loss in potential tonnage due to limiting water depth (the tonnage at LoadCapacity)\n",
    "      reaction: increase in number of trips due to limiting water depth\n",
    "      reaction: increase in sailing costs due to limiting water depth\n",
    "    \n",
    "    \"\"\"\n",
    "    # Decrease in load (0 to 100%)\n",
    "    load_decrease = 1 - ((trips['Depth__m'] - depth) * 100 * trips['TPCMI']) / trips['Totale Vracht (ton)']\n",
    "    load_decrease.clip(lower=0, upper=1, inplace=True)  # Maximum realistic limits\n",
    "    load_decrease.fillna(0, inplace=True)  # For empty vessels \n",
    "\n",
    "    # Effect: decrease in tonnage\n",
    "    tonnage = load_decrease.clip(lower=0, upper=1) * trips_subset['Totale Vracht (ton)']\n",
    "    \n",
    "    # Effect: (does not work for empty ships!)\n",
    "#     tonnage_potential = (load_decrease.clip(lower=0) * trips['Beladingsgraad']).clip(upper=1) * trips['LoadCapacity__t']\n",
    "    \n",
    "    beladingsgraad_potential = ((depth - trips['Ledige_diepgang']) / (trips['Maximale_diepgang'] - trips['Ledige_diepgang']))\n",
    "    beladingsgraad_potential.clip(lower=0, upper=1, inplace=True)\n",
    "    beladingsgraad_potential.fillna(0, inplace=True)  # Nans exist because of vessel with loadcapacity=0\n",
    "    tonnage_potential = beladingsgraad_potential * trips['LoadCapacity__t']\n",
    "\n",
    "    # Reaction: Minimal of 0.2 (so max 80% reduction), maximum of 1.0 (no change)\n",
    "    load_decrease.clip(lower=0.2, upper=1, inplace=True)\n",
    "    trips_increase = load_decrease ** -1\n",
    "    \n",
    "    # Reaction: increase in (variable) costs and number of trips\n",
    "    costs_n = trips['Totale Vaste Vaarkosten (EUR)'] + trips['Totale Variabele Vaarkosten (EUR)'] * trips_increase\n",
    "    trips_n = trips['Aantal Vaarbewegingen (-)'] * trips_increase  # This is only necessary if in the original data the trips != 1\n",
    "    \n",
    "    response = pd.DataFrame(\n",
    "        index = trips.index,\n",
    "        data = {\n",
    "            'trips affected': ((trips['Depth__m'] > depth) * trips['Aantal Vaarbewegingen (-)']),\n",
    "            'tonnage' : tonnage,\n",
    "            'tonnage potential' : tonnage_potential,\n",
    "            'costs' : costs_n,\n",
    "            'trips' : trips_n,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "#     response_total = response.sum()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each route, get effect of a lowering waterdepth based on all ships passing on this (unique) route\n",
    "all_depths = np.linspace(0, 10, 101)\n",
    "all_depths = np.round(all_depths, 2)\n",
    "\n",
    "effect_and_reaction = {}\n",
    "\n",
    "for ks, tripids in tqdm(i_per_group.items()):\n",
    "    \n",
    "    # Get all trips on route in the full year\n",
    "    trips_subset = trips.reindex(tripids)\n",
    "    \n",
    "    # Compute effect on tonnage and reaction in trips and costs\n",
    "    effect_and_reaction[ks] = pd.DataFrame(\n",
    "        data=[costs(trips_subset,  depth).sum() for depth in all_depths], \n",
    "        index=all_depths,\n",
    "    )\n",
    "    \n",
    "effect_and_reaction = pd.concat(effect_and_reaction, axis=1).T.swaplevel(axis=0)\n",
    "\n",
    "# Convert to per day\n",
    "effect_and_reaction = effect_and_reaction / 365\n",
    "\n",
    "totalcosts = effect_and_reaction.loc['costs']\n",
    "    \n",
    "# Export totalcosts for use in model\n",
    "params = effect_and_reaction.index.levels[0]\n",
    "for param in params:\n",
    "    exportdata = effect_and_reaction.loc[param]\n",
    "    exportdata.reset_index().rename(columns={'index': 'routes'}).to_json(outputdir / f'route_depth_{param}.json', double_precision=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Same but with additional subgroups. Not using this output yet anywhere...\n",
    "# # For each route, get effect of a lowering waterdepth based on all ships passing on this (unique) route\n",
    "# all_depths = np.linspace(0, 10, 101)\n",
    "# all_depths = np.round(all_depths, 2)\n",
    "\n",
    "# effect_and_reaction_subgroups = {}\n",
    "# groups = ['Origin_Zone', 'Destination_Zone', 'Vorm']\n",
    "\n",
    "# for ks, tripids in i_per_group.items():\n",
    "    \n",
    "#     # Get all trips on route in the full year\n",
    "#     trips_subset = trips.reindex(tripids)\n",
    "    \n",
    "#     groupby_subset = trips_subset.groupby(groups)\n",
    "\n",
    "#     # Compute effect on tonnage and reaction in trips and costs\n",
    "#     route_effect_and_reaction = {}\n",
    "#     for depth in tqdm(all_depths):\n",
    "#         response = costs(trips_subset,  depth)\n",
    "\n",
    "#         response_grouped = {}\n",
    "#         for k, i in groupby_subset.indices.items():\n",
    "#             id = trips_subset.index[i]\n",
    "#             response_grouped[k] = response.reindex(id, axis=0).sum()\n",
    "#         response_grouped = pd.concat(response_grouped, axis=0)\n",
    "#         route_effect_and_reaction[depth] = response_grouped\n",
    "#     route_effect_and_reaction = pd.concat(route_effect_and_reaction, axis=0).unstack(level=0).T\n",
    "    \n",
    "#     effect_and_reaction_subgroups[ks] = route_effect_and_reaction\n",
    "\n",
    "# effect_and_reaction_subgroups = pd.concat(effect_and_reaction_subgroups, axis=1)\n",
    "\n",
    "# # Convert to per day\n",
    "# effect_and_reaction_subgroups = effect_and_reaction_subgroups / 365\n",
    "\n",
    "# # Export totalcosts for use in model\n",
    "# totalcosts_subgroups = effect_and_reaction_subgroups.xs('costs', axis=1, level=-1)\n",
    "# totalcosts_subgroups.reset_index().rename(columns={'index': 'routes'}).to_json(outputdir / 'route_depth_costs_subgroups.json', double_precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some postprocessing and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot QH\n",
    "styles = ['-'] * 10 +  [':'] * 10 \n",
    "QH.T.plot(style=styles)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1,0.5))\n",
    "plt.grid(c='#DDD')\n",
    "plt.autoscale('x', tight=True)\n",
    "plt.ylim(1, 6)\n",
    "plt.xlabel('Afvoer ($m^3/s$)')\n",
    "plt.ylabel('Waterdiepte (m)')\n",
    "# plt.savefig(outputdir / 'knelpunt_discharge_waterdepth.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot QH\n",
    "f, ax = plt.subplots(nrows=4, figsize=(6, 10), sharey=True, sharex=True)\n",
    "ii = 0\n",
    "for a in ax:\n",
    "    plt.sca(a)\n",
    "    QH.T.iloc[:, ii:ii+6].plot(style=styles, ax=a)\n",
    "    \n",
    "    ii += 6\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1,0.5))\n",
    "    plt.grid(c='#DDD')\n",
    "    plt.ylabel('Waterdiepte (m)')\n",
    "plt.autoscale('x', tight=True)\n",
    "plt.ylim(1, 5)\n",
    "plt.xlabel('Afvoer ($m^3/s$)')\n",
    "plt.savefig(outputdir / 'knelpunt_discharge_waterdepth_grid.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot effect of reducing depth per route\n",
    "# plotdata = totalcosts.sort_values(10.0, axis=0, ascending=False).loc[:, 1.5:3]\n",
    "# plotdata = plotdata.sort_index(axis=1, ascending=False).diff(axis=1).fillna(plotdata)\n",
    "\n",
    "# plotdata.plot.barh(figsize=(10, 4), stacked=True, width=0.8, cmap='Blues', zorder=3)\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.legend(loc='center left', bbox_to_anchor=(1,0.5), title='Beschikbare diepgang (m)')\n",
    "(totalcosts.sort_values(10.0, axis=0, ascending=False).T / 1e6).iloc[:, 1:15].plot()\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.1,0.5), title='Route')\n",
    "plt.ylabel('Transportkosten per dag (mln eur)')\n",
    "plt.xlabel('Diepgang (m)')\n",
    "plt.xlim(0.5, 3.5)\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(outputdir / 'route_depth_costs.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should multiply by nTrips\n",
    "plotdata = (knelpunt_route.sum() / 365).sort_values(ascending=False)\n",
    "plotdata.plot.bar(width=0.8, zorder=3)\n",
    "plt.ylabel('Aantal passages per dag')\n",
    "plt.grid()\n",
    "plt.savefig(outputdir / 'knelpunten_passages_per_dag.png', dpi=300, bbox_inches='tight')\n",
    "plotdata.to_csv(outputdir / 'knelpunten_passages_per_dag.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence per knelpunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_and_interpolate(df, new_index):\n",
    "    return df.reindex(df.index | new_index).interpolate(method='index', limit_direction='both').loc[new_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltrips_sum = {}\n",
    "mintrips_sum = {}\n",
    "\n",
    "# Loop over all knelpunten\n",
    "for k in tqdm(knelpunt_arcs.keys()):\n",
    "\n",
    "    # Get all routes which pass the knelpunt\n",
    "    ii_routes_with_k = [k in totalcosts.index[ii] for ii in range(totalcosts.shape[0])]\n",
    "    routes_with_k = totalcosts.index[ii_routes_with_k]\n",
    "\n",
    "\n",
    "    # For each route, compute the number of influenced trip at each depth (both: all trips, and trips where this knelpunt is limiting)\n",
    "    alltrips = {}\n",
    "    mintrips = {}\n",
    "\n",
    "    # For each route\n",
    "    for r in routes_with_k:\n",
    "\n",
    "        # Get QH for all knelpunten on route\n",
    "        r_QH = QH.loc[r].T\n",
    "\n",
    "        # Convert to relation depth_k-depth_other_k \n",
    "        r_HH = r_QH.copy()\n",
    "        r_HH.index = r_HH.loc[:, k]\n",
    "        r_HH = r_HH[~r_HH.index.duplicated(keep='first')]  # On duplicate index (=depth) only keep first\n",
    "        r_HH = reindex_and_interpolate(r_HH, all_depths)  # Reindex to range\n",
    "        \n",
    "\n",
    "        # Get index of all depths where k is minimal\n",
    "        k_minimal = r_HH.idxmin(axis=1) == k\n",
    "\n",
    "        # Get number of affected trips (per waterdepth)\n",
    "        alltrips[r] = effect_and_reaction.xs(r, axis=0, level=1)\n",
    "        mintrips[r] = alltrips[r].loc[:, k_minimal].reindex(all_depths, axis=1).fillna(0)\n",
    "\n",
    "    alltrips = pd.concat(alltrips, axis=1).T\n",
    "    mintrips = pd.concat(mintrips, axis=1).T\n",
    "    \n",
    "    # Sum over all routes passing given knelpunt, resulting in DataFrame(index=depth, columns=[trips affected, etc.])\n",
    "    alltrips_sum[k] = alltrips.sum(axis=0, level=1)\n",
    "    mintrips_sum[k] = mintrips.sum(axis=0, level=1)\n",
    "\n",
    "alltrips_sum = pd.concat(alltrips_sum, axis=1).swaplevel(axis=1).sort_index(axis=1)\n",
    "mintrips_sum = pd.concat(mintrips_sum, axis=1).swaplevel(axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation, should be 0\n",
    "trips['Aantal Vaarbewegingen (-)'].sum() - effect_and_reaction.loc['trips affected'].iloc[0, 0]*365 - mintrips_sum['trips affected'].sum(axis=1).iloc[0]*365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trips per route\n",
    "# effect_and_reaction.loc['trips', 10].sort_values(ascending=False)\n",
    "\n",
    "# Number of tirps per knelpunt\n",
    "# alltrips_sum['trips'].loc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(ncols=2, figsize=(10, 6), sharey=True)\n",
    "plt.sca(ax[0])\n",
    "plotdata = alltrips_sum.sort_values(axis=1, by=0, ascending=False)['trips affected']\n",
    "plotdata.plot(cmap='tab20_r', legend=False, ax=ax[0])\n",
    "plt.grid()\n",
    "# plt.legend(bbox_to_anchor=(1,1))\n",
    "plt.xlabel('Beschikbare diepgang (m)')\n",
    "plt.ylabel('Aantal reizen beinvloed')\n",
    "plt.title('Ongeacht andere knelpunten')\n",
    "\n",
    "plt.sca(ax[1])\n",
    "mintrips_sum['trips affected'][plotdata.columns].plot(cmap='tab20_r', ax=ax[1])\n",
    "plt.grid()\n",
    "plt.legend(bbox_to_anchor=(1,1))\n",
    "plt.xlabel('Beschikbare diepgang (m)')\n",
    "plt.ylabel('Aantal reizen beinvloed')\n",
    "plt.title('Beschouwde knelpunt maatgevend')\n",
    "# plt.ylim(top=10000)\n",
    "\n",
    "plt.savefig(outputdir / 'Effect_knelpunten.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(ncols=2, figsize=(10, 6), sharey=True, sharex=True)\n",
    "plt.ylim(0,1.05)\n",
    "plt.xlim(0, 5)\n",
    "plt.sca(ax[0])\n",
    "plotdata = alltrips_sum.sort_values(axis=1, by=0, ascending=False)['trips affected']\n",
    "maxtrips = plotdata.loc[0]\n",
    "plotdata_normed = plotdata / maxtrips\n",
    "# Normalise \n",
    "plotdata_normed.plot(cmap='tab20_r', legend=False, ax=ax[0])\n",
    "plt.grid()\n",
    "# plt.legend(bbox_to_anchor=(1,1))\n",
    "plt.xlabel('Beschikbare diepgang (m)')\n",
    "plt.ylabel('Aantal reizen beinvloed')\n",
    "plt.title('Ongeacht andere knelpunten')\n",
    "\n",
    "plt.sca(ax[1])\n",
    "plotdata2 = mintrips_sum['trips affected'][plotdata.columns] / maxtrips\n",
    "plotdata2.plot(cmap='tab20_r', ax=ax[1])\n",
    "plt.grid()\n",
    "plt.legend(bbox_to_anchor=(1,0.5), loc='center left')\n",
    "plt.xlabel('Beschikbare diepgang (m)')\n",
    "plt.ylabel('Aantal reizen beinvloed')\n",
    "plt.title('Beschouwde knelpunt maatgevend')\n",
    "\n",
    "plt.savefig(outputdir / 'Effect_knelpunten.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata = alltrips_sum.sort_values(axis=1, by=0, ascending=False)['trips affected']\n",
    "maxtrips = plotdata.loc[0]\n",
    "plotdata_normed = plotdata / maxtrips\n",
    "plotdata2 = mintrips_sum['trips affected'][plotdata.columns]\n",
    "plotdata2_normed = plotdata2 / maxtrips\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(6, 4, sharex=True, sharey=True, figsize=(10,10))\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "ax = ax.flatten()\n",
    "\n",
    "for ii, name in enumerate(QH.index):\n",
    "    data = plotdata2_normed[name]\n",
    "    plt.sca(ax[ii])\n",
    "    plt.title(name)\n",
    "    plt.fill_between(data.index, data.values)\n",
    "    plt.annotate('{:.1f}'.format(maxtrips[name]), (0.1, 0.05), color='w')\n",
    "    ax[ii].set_facecolor('C3')\n",
    "    plotdata_normed[name].plot(ax=ax[ii], ls=':', c='k')\n",
    "plt.xlim(0.8, 4.1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.xlabel(f'Waterdiepte (m)')\n",
    "\n",
    "ax[ii+1].set_axis_off()\n",
    "ax[ii+2].set_axis_off()\n",
    "\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()]);\n",
    "\n",
    "plt.savefig(outputdir / 'Knelpunten_perc_reizen_beinvloed_WL.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar analyses, now per discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function computes for different discharges: (1) what are the [params] if all ships passing a knelpunt are effected. \n",
    "\n",
    "alltrips_sum = {}\n",
    "mintrips_sum = {}\n",
    "\n",
    "def interp(df, new_index):\n",
    "    \"\"\"Return a new DataFrame with all columns values interpolated\n",
    "    to the new_index values.\"\"\"\n",
    "    df_out = pd.DataFrame(index=new_index)\n",
    "    df_out.index.name = df.index.name\n",
    "\n",
    "    for colname, col in df.iteritems():\n",
    "        df_out[colname] = np.interp(new_index, df.index, col)\n",
    "\n",
    "    return df_out\n",
    "\n",
    "alltrips = {}\n",
    "mintrips = {}\n",
    "routes = totalcosts.index\n",
    "\n",
    "route_costs_Q = {}\n",
    "\n",
    "ukc=0.2\n",
    "\n",
    "for r in routes:\n",
    "    # Get depth at all knelpunten on route\n",
    "    r_QH = QH.loc[r].T\n",
    "    \n",
    "    # Get the depth-costs relation for this route\n",
    "    response_on_route = effect_and_reaction.xs(r, axis=0, level=1)\n",
    "    \n",
    "    # Get total costs on this route\n",
    "    min_depth_on_route = r_QH.min(axis=1).fillna(999)  # FIllna for route ()\n",
    "    min_depth_on_route -= ukc\n",
    "\n",
    "    route_costs_Q[r] = interp(response_on_route.T, min_depth_on_route.values)\n",
    "    route_costs_Q[r].index = r_QH.index\n",
    "    route_costs_Q[r]['costs_increase'] = route_costs_Q[r]['costs'] - route_costs_Q[r]['costs'][1800]\n",
    "    \n",
    "    for k in r:\n",
    "        # Get number of affected trips (per waterdepth)\n",
    "        depth_at_k = r_QH[k].values - ukc\n",
    "        \n",
    "        # Interpolate costs to discharge levels\n",
    "        alltrips[(r, k)] = interp(response_on_route.T, depth_at_k)\n",
    "        alltrips[(r, k)].index = r_QH.index\n",
    "        alltrips[(r, k)]['costs_increase'] = alltrips[(r, k)]['costs'] - alltrips[(r, k)]['costs'][1800]\n",
    "\n",
    "        # Only select those levels where k is the minimum depth on the route\n",
    "        k_minimal = r_QH.idxmin(axis=1) == k\n",
    "        mintrips[(r, k)] = route_costs_Q[r].mul(k_minimal, axis=0)\n",
    "\n",
    "alltrips = pd.concat(alltrips)        \n",
    "mintrips = pd.concat(mintrips)\n",
    "route_costs_Q = pd.concat(route_costs_Q, axis=1)\n",
    "\n",
    "alltrips_sum = alltrips.unstack(level=1).sum(axis=0, level=1)\n",
    "mintrips_sum = mintrips.unstack(level=1).sum(axis=0, level=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no other knelpunten exists:\n",
    "plotdata = alltrips_sum['trips affected']\n",
    "maxtrips = alltrips_sum['trips'].loc[1800]\n",
    "plotdata_normed = plotdata / maxtrips\n",
    "\n",
    "# Taking into account other knelpunten\n",
    "plotdata2 = mintrips_sum['trips affected'][plotdata.columns]\n",
    "plotdata2_normed = plotdata2 / maxtrips\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(6, 4, sharex=True, sharey=True, figsize=(10,10))\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "ax = ax.flatten()\n",
    "\n",
    "for ii, name in enumerate(QH.index):\n",
    "    data = plotdata2_normed[name]\n",
    "    plt.sca(ax[ii])\n",
    "    plt.title(name)\n",
    "    plt.fill_between(data.index, data.values)\n",
    "    plt.annotate('Total: {:.1f}'.format(maxtrips[name]), (0.95, 0.95), color='w', xycoords='axes fraction', ha='right', va='top')\n",
    "    ax[ii].set_facecolor('C3')\n",
    "    plotdata_normed[name].plot(ax=ax[ii], ls=':', c='k')\n",
    "plt.xlim(plotdata2.index[0], plotdata2.index[-1])\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(f'Afvoer Lobith ($m^3/s$)')\n",
    "\n",
    "ax[ii+1].set_axis_off()\n",
    "ax[ii+2].set_axis_off()\n",
    "\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()]);\n",
    "\n",
    "plt.savefig(outputdir / 'Knelpunten_perc_reizen_beinvloed_Q.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inverselegend(outside=False, **kwargs):\n",
    "    if outside:\n",
    "        return plt.gca().legend(*map(reversed, plt.gca().get_legend_handles_labels()), loc='center left',\n",
    "                         bbox_to_anchor=(1, 0.5), **kwargs)\n",
    "    else:\n",
    "        return plt.gca().legend(*map(reversed, plt.gca().get_legend_handles_labels()), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata2 = mintrips_sum['trips affected'][plotdata.columns]\n",
    "plotdata2= plotdata2.sort_values(axis=1, by=700, ascending=False)\n",
    "pc = plt.stackplot(plotdata2.index, plotdata2.T, labels=plotdata2.columns[:10], zorder=3)\n",
    "plt.legend(plotdata2.columns[:10])\n",
    "plt.grid()\n",
    "plt.xlim(plotdata2.index[0], plotdata2.index[-1])\n",
    "inverselegend()\n",
    "plt.xlabel(f'Afvoer Lobith ($m^3/s$)')\n",
    "plt.ylabel('Aantal reizen per dag')\n",
    "plt.title('Reizen beperkt door knelpunt')\n",
    "\n",
    "plt.savefig(outputdir / 'Knelpunten_cum_reizen.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata2 = mintrips_sum['costs_increase'].fillna(0)\n",
    "plotdata2= plotdata2 / 1e6\n",
    "plotdata2 = plotdata2.sort_values(axis=1, by=700, ascending=False)\n",
    "\n",
    "pc = plt.stackplot(plotdata2.index, plotdata2.T[:10], labels=plotdata2.columns[:10], zorder=3)\n",
    "plt.legend(plotdata2.columns)\n",
    "plt.grid()\n",
    "plt.xlim(plotdata2.index[0], plotdata2.index[-1])\n",
    "inverselegend()\n",
    "plt.xlabel(f'Afvoer Lobith ($m^3/s$)')\n",
    "plt.ylabel('Toename vaarkosten per dag (mln euro)')\n",
    "plt.title('Toename kosten per knelpunt')\n",
    "\n",
    "plt.savefig(outputdir / 'Knelpunten_cum_costs.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
